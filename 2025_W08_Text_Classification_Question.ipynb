{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7DGbuYtB1JI",
        "outputId": "84e9f260-90a4-43a0-9081-9c8b44a6432d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Lr_aNnDihp2r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Copy of trum_tweet_sentiment_analysis (1).csv')"
      ],
      "metadata": {
        "id": "dHUoAgPOiR3D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "orFmH2pulwjg",
        "outputId": "f48c7765-af9b-49e4-f4dd-3e1858e2f049"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      text  Sentiment\n",
              "0        RT @JohnLeguizamo: #trump not draining swamp b...          0\n",
              "1        ICYMI: Hackers Rig FM Radio Stations To Play A...          0\n",
              "2        Trump protests: LGBTQ rally in New York https:...          1\n",
              "3        \"Hi I'm Piers Morgan. David Beckham is awful b...          0\n",
              "4        RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...          0\n",
              "...                                                    ...        ...\n",
              "1850118  Everytime im like 'How the fuck I follow Melan...          0\n",
              "1850119  RT @imgur: The Trump Handshake. https://t.co/R...          0\n",
              "1850120  \"Greenspan warns Trump's policies risk inflati...          0\n",
              "1850121  RT @FasinatingLogic: We must also #INVESTIGATE...          1\n",
              "1850122  RT @imgur: The Trump Handshake. https://t.co/R...          0\n",
              "\n",
              "[1850123 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d4bcb2d-587d-4182-b482-5ac891df33d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @JohnLeguizamo: #trump not draining swamp b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ICYMI: Hackers Rig FM Radio Stations To Play A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trump protests: LGBTQ rally in New York https:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Hi I'm Piers Morgan. David Beckham is awful b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850118</th>\n",
              "      <td>Everytime im like 'How the fuck I follow Melan...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850119</th>\n",
              "      <td>RT @imgur: The Trump Handshake. https://t.co/R...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850120</th>\n",
              "      <td>\"Greenspan warns Trump's policies risk inflati...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850121</th>\n",
              "      <td>RT @FasinatingLogic: We must also #INVESTIGATE...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850122</th>\n",
              "      <td>RT @imgur: The Trump Handshake. https://t.co/R...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1850123 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d4bcb2d-587d-4182-b482-5ac891df33d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d4bcb2d-587d-4182-b482-5ac891df33d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d4bcb2d-587d-4182-b482-5ac891df33d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb63b2d9-6bc6-4d47-b12b-c702100aac4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb63b2d9-6bc6-4d47-b12b-c702100aac4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb63b2d9-6bc6-4d47-b12b-c702100aac4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bd901ec7-9f39-46b7-b82e-987055e9d5d1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bd901ec7-9f39-46b7-b82e-987055e9d5d1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_text=df['text']"
      ],
      "metadata": {
        "id": "5rl39PrTjj1V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentiment=df[\"Sentiment\"]\n",
        "df_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "TgoNTm_els0a",
        "outputId": "f245bff9-3ecd-4d8b-f91b-29ff9c982f6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          0\n",
              "1          0\n",
              "2          1\n",
              "3          0\n",
              "4          0\n",
              "          ..\n",
              "1850118    0\n",
              "1850119    0\n",
              "1850120    0\n",
              "1850121    1\n",
              "1850122    0\n",
              "Name: Sentiment, Length: 1850123, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850118</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850119</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850120</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850121</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850122</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1850123 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_text.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "HzMvbI2Ajr2-",
        "outputId": "e07e6375-209d-41ec-b7ed-26c0b852eb1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          RT @JohnLeguizamo: #trump not draining swamp b...\n",
              "1          ICYMI: Hackers Rig FM Radio Stations To Play A...\n",
              "2          Trump protests: LGBTQ rally in New York https:...\n",
              "3          \"Hi I'm Piers Morgan. David Beckham is awful b...\n",
              "4          RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...\n",
              "                                 ...                        \n",
              "1850118    Everytime im like 'How the fuck I follow Melan...\n",
              "1850119    RT @imgur: The Trump Handshake. https://t.co/R...\n",
              "1850120    \"Greenspan warns Trump's policies risk inflati...\n",
              "1850121    RT @FasinatingLogic: We must also #INVESTIGATE...\n",
              "1850122    RT @imgur: The Trump Handshake. https://t.co/R...\n",
              "Name: text, Length: 1850123, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @JohnLeguizamo: #trump not draining swamp b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ICYMI: Hackers Rig FM Radio Stations To Play A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trump protests: LGBTQ rally in New York https:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Hi I'm Piers Morgan. David Beckham is awful b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @GlennFranco68: Tech Firm Suing BuzzFeed fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850118</th>\n",
              "      <td>Everytime im like 'How the fuck I follow Melan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850119</th>\n",
              "      <td>RT @imgur: The Trump Handshake. https://t.co/R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850120</th>\n",
              "      <td>\"Greenspan warns Trump's policies risk inflati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850121</th>\n",
              "      <td>RT @FasinatingLogic: We must also #INVESTIGATE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850122</th>\n",
              "      <td>RT @imgur: The Trump Handshake. https://t.co/R...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1850123 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_urls(text):\n",
        "  \"\"\"\n",
        "  This function will try to remove URL present in out dataset and replace it with space using regex library.\n",
        "  Input Args:\n",
        "  text: strings of text that may contain URLs.\n",
        "  Output Args:\n",
        "  text: URLs replaces with text\n",
        "  \"\"\"\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  return url_pattern.sub(r'', text)\n",
        "def remove_emoji(string):\n",
        "  \"\"\"\n",
        "  This function will replace the emoji in string with whitespace\n",
        "  \"\"\"\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  return emoji_pattern.sub(r' ', string)\n",
        "def removeunwanted_characters(document):\n",
        "  \"\"\"\n",
        "  This function will remove all the unwanted characters from the input dataset.\n",
        "  Input Args:\n",
        "  documet: A text data to be cleaned.\n",
        "  Return:\n",
        "  A cleaned document.\n",
        "  \"\"\"\n",
        "  # remove user mentions\n",
        "  document = re.sub(\"@[A-Za-z0-9_]+\",\" \", document)\n",
        "  # remove hashtags\n",
        "  document = re.sub(\"#[A-Za-z0-9_]+\",\"\", document)\n",
        "  # remove punctuation\n",
        "  document = re.sub(\"[^0-9A-Za-z ]\", \"\" , document)\n",
        "  #remove emojis\n",
        "  document = remove_emoji(document)\n",
        "  # remove double spaces\n",
        "  document = document.replace('  ',\"\")\n",
        "  return document.strip()\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "def remove_punct(text):\n",
        "  \"\"\"\n",
        "  This function removes the punctutations present in our text data.\n",
        "  Input Args:\n",
        "  text: text data.\n",
        "  Returns:\n",
        "  text: cleaned text.\n",
        "  \"\"\"\n",
        "  tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "  lst=tokenizer.tokenize(' '.join(text))\n",
        "  return lst\n",
        "def lower_order(text):\n",
        "  \"\"\"\n",
        "  This function converts all the text in input text to lower order.\n",
        "  Input Args:\n",
        "  token_text : input text.\n",
        "  Returns:\n",
        "  small_order_text : text converted to small/lower order.\n",
        "  \"\"\"\n",
        "  small_order_text = text.lower()\n",
        "  return small_order_text\n",
        "\n",
        "# Test:\n",
        "sample_text = \"This Is some Normalized TEXT\"\n",
        "sample_small = lower_order(sample_text)\n",
        "print(sample_small)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEc19Qanj7pb",
        "outputId": "ac4cefc2-4847-4708-e431-343667ffb2e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is some normalized text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aximiXfdkM2H",
        "outputId": "0a8684a1-9773-4863-cf54-a4aba60ff59e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "custom_stopwords = ['@', 'RT']\n",
        "stop_words.update(custom_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsxgHnASkWCz",
        "outputId": "577da076-d0ce-4b9b-e362-b63e4cefa275"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_stopwords(text_tokens):\n",
        "  \"\"\"\n",
        "  This function removes all the stopwords present in out text tokens.\n",
        "  Input Args:\n",
        "  text_tokens: tokenize input of our datasets.\n",
        "  Returns:\n",
        "  result_tokens: list of token without stopword.\n",
        "  \"\"\"\n",
        "\n",
        "  result_tokens = []\n",
        "  for token in text_tokens:\n",
        "    if token not in stop_words:\n",
        "       result_tokens.append(token)\n",
        "  return result_tokens"
      ],
      "metadata": {
        "id": "Df7WM68rkbNb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def stemming(text):\n",
        "  \"\"\"\n",
        "  This function performs stemming operations.\n",
        "  Input Args:\n",
        "  token_text: list of tokenize text.\n",
        "  Returns:\n",
        "  stemm_tokes: list of stemmed tokens.\n",
        "  \"\"\"\n",
        "  porter = PorterStemmer()\n",
        "  stemm_tokens = []\n",
        "  for word in text:\n",
        "    stemm_tokens.append(porter.stem(word))\n",
        "  return stemm_tokens"
      ],
      "metadata": {
        "id": "g15M0a7mlLzV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize,pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def lemmatization(token_text):\n",
        "  \"\"\"\n",
        "  This function performs the lemmatization operations as explained above.\n",
        "  Input Args:\n",
        "  token_text: list of tokens.\n",
        "  Returns:\n",
        "  lemmatized_tokens: list of lemmatized tokens.\n",
        "  \"\"\"\n",
        "  lemma_tokens = []\n",
        "  wordnet = WordNetLemmatizer()\n",
        "  lemmatized_tokens = [wordnet.lemmatize(token, pos = 'v') for token in token_text]\n",
        "\n",
        "  return lemmatized_tokens\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiZaY3iMkcNt",
        "outputId": "3df0551b-a4b6-4285-d3b4-349ac9bd353a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "print(\"+++++++++++++++++++++++++++++++\" \"INPUT TOKENS\" \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "token_text_test=['Connects','Connecting','Connections','Connected','Connection','Connectings','Connect']\n",
        "print(token_text_test)\n",
        "print(\"++++++++++++++++++\" \"LEMMATIZED TOKENS\" \"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
        "lemma_tokens = lemmatization(token_text_test)\n",
        "print(lemma_tokens)\n",
        "print(\"+++++++++++++++++++++\" \"STEMMED TOKENS\" \"+++++++++++++++++++++++++++++++++++++\")\n",
        "lemma_tokens = lemmatization(token_text_test)\n",
        "print(lemma_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLD3L2g9kjuz",
        "outputId": "908a4ca4-8986-4120-eb8c-90045d0893d4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+++++++++++++++++++++++++++++++INPUT TOKENS++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "['Connects', 'Connecting', 'Connections', 'Connected', 'Connection', 'Connectings', 'Connect']\n",
            "++++++++++++++++++LEMMATIZED TOKENS+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "['Connects', 'Connecting', 'Connections', 'Connected', 'Connection', 'Connectings', 'Connect']\n",
            "+++++++++++++++++++++STEMMED TOKENS+++++++++++++++++++++++++++++++++++++\n",
            "['Connects', 'Connecting', 'Connections', 'Connected', 'Connection', 'Connectings', 'Connect']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Function for Text Cleaning:\n",
        "\n",
        "Implement a Helper Function as per Text Preprocessing Notebook and Complete the following pipeline."
      ],
      "metadata": {
        "id": "SxV-QBHp-B6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Text Cleaning Pipeline"
      ],
      "metadata": {
        "id": "B-llg-TI_Drw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_order(text):\n",
        "  \"\"\"\n",
        "  This function converts all the text in input text to lower order.\n",
        "  Input Args:\n",
        "  token_text : input text.\n",
        "  Returns:\n",
        "  small_order_text : text converted to small/lower order.\n",
        "  \"\"\"\n",
        "  small_order_text = text.lower()\n",
        "  return small_order_text\n",
        "\n",
        "# Test:\n",
        "sample_text = \"This Is some Normalized TEXT\"\n",
        "sample_small = lower_order(sample_text)\n",
        "print(sample_small)\n"
      ],
      "metadata": {
        "id": "rwLrn6yephN8",
        "outputId": "659b3814-7e59-46ae-a618-45059ffe0760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is some normalized text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the stemmer and lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Download stopwords if not already done\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Add necessary cleaning functions (placeholders for your actual implementations)\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "\n",
        "def remove_emoji(text):\n",
        "    return text.encode('ascii', 'ignore').decode('ascii')\n",
        "\n",
        "def remove_unwanted_characters(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "\n",
        "# Text cleaning pipeline function\n",
        "def text_cleaning_pipeline(dataset, rule=\"stem\"):\n",
        "    \"\"\"\n",
        "    This function cleans the text data: removes URLs, emojis, unwanted characters,\n",
        "    tokenizes, removes stopwords, and applies stemming or lemmatization.\n",
        "    \"\"\"\n",
        "    # Convert the input to lower case\n",
        "    data = dataset.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    data = remove_urls(data)\n",
        "\n",
        "    # Remove emojis\n",
        "    data = remove_emoji(data)\n",
        "\n",
        "    # Remove unwanted characters\n",
        "    data = remove_unwanted_characters(data)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(data)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Apply stemming or lemmatization\n",
        "    if rule == \"lemmatize\":\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    elif rule == \"stem\":\n",
        "        tokens = [stemmer.stem(word) for word in tokens]\n",
        "    else:\n",
        "        print(\"Pick between lemmatize or stem\")\n",
        "\n",
        "    # Return the cleaned text as a string\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Example: Apply the cleaning pipeline\n",
        "X = df['text']  # Assuming you have a column 'text' in your dataframe\n",
        "cleaned_text = X.apply(lambda x: text_cleaning_pipeline(x, rule=\"lemmatize\"))\n",
        "\n",
        "# Print the cleaned text for verification\n",
        "print(cleaned_text.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcRFsoR1lDXY",
        "outputId": "e7700098-c093-4898-ed7b-597091ef4efd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    rt johnleguizamo trump draining swamp taxpayer...\n",
            "1    icymi hacker rig fm radio station play antitru...\n",
            "2    trump protest lgbtq rally new york bbcworld vi...\n",
            "3    hi im pier morgan david beckham awful donald t...\n",
            "4    rt glennfranco68 tech firm suing buzzfeed publ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting"
      ],
      "metadata": {
        "id": "aszYQPGBlf0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "CTU6p2U1lj5U"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Sentiment']\n",
        "\n",
        "# 2. Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "   cleaned_text , y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. TF-IDF Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# 4. Model Training\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)   # .ravel() is optional if y_train is already Series\n",
        "\n",
        "# 5. Prediction + Report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFgmFdBDlfff",
        "outputId": "969f1372-9ce8-4509-aea8-00111bcaceb5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96    373110\n",
            "           1       0.92      0.89      0.91    181927\n",
            "\n",
            "    accuracy                           0.94    555037\n",
            "   macro avg       0.94      0.93      0.93    555037\n",
            "weighted avg       0.94      0.94      0.94    555037\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vk0jPrWll5Ug"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qsymNFiLl7Ys"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification using Machine Learning Models\n"
      ],
      "metadata": {
        "id": "hzMm4-1KCNkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 Instructions: Trump Tweet Sentiment Classification\n",
        "\n",
        "1. **Load the Dataset**  \n",
        "   Load the dataset named `\"trump_tweet_sentiment_analysis.csv\"` using `pandas`. Ensure the dataset contains at least two columns: `\"text\"` and `\"label\"`.\n",
        "\n",
        "2. **Text Cleaning and Tokenization**  \n",
        "   Apply a text preprocessing pipeline to the `\"text\"` column. This should include:\n",
        "   - Lowercasing the text  \n",
        "   - Removing URLs, mentions, punctuation, and special characters  \n",
        "   - Removing stopwords  \n",
        "   - Tokenization (optional: stemming or lemmatization)\n",
        "   - \"Complete the above function\"\n",
        "\n",
        "3. **Train-Test Split**  \n",
        "   Split the cleaned and tokenized dataset into **training** and **testing** sets using `train_test_split` from `sklearn.model_selection`.\n",
        "\n",
        "4. **TF-IDF Vectorization**  \n",
        "   Import and use the `TfidfVectorizer` from `sklearn.feature_extraction.text` to transform the training and testing texts into numerical feature vectors.\n",
        "\n",
        "5. **Model Training and Evaluation**  \n",
        "   Import **Logistic Regression** (or any machine learning model of your choice) from `sklearn.linear_model`. Train it on the TF-IDF-embedded training data, then evaluate it using the test set.  \n",
        "   - Print the **classification report** using `classification_report` from `sklearn.metrics`.\n"
      ],
      "metadata": {
        "id": "oFltIxr9L2Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZKKasna7q3B1"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}